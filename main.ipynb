{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "90d251e6",
   "metadata": {},
   "source": [
    "## IMPORT LIBRARIES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e8824634",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca98a2ac",
   "metadata": {},
   "source": [
    "## LOAD TRAINING IMAGES AND LABELS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32c3174b",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"data/MNIST/raw/train-images-idx3-ubyte\",\"rb\") as f:\n",
    "    f.read(16) #skipping the first 16 bytes which are header\n",
    "    data = f.read() \n",
    "    images = np.frombuffer(data, dtype = np.uint8) # converting images to numpy array  of type uint8\n",
    "    images = images.reshape(-1,1,28,28) #-1 letting numpy figure out the number of images, 1 because we are only taking grayscale: 1 color channel, 28 * 28 is the image dimension\n",
    "    images = images.astype(np.float32)/255.0  # normalizing pixel values [0,1] by dividing by 255 as the pixel value ranges from 0-255, so now its [0,1]\n",
    "    images_tensor = torch.from_numpy(images) # coverts numpy array to pytorch tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1efe1ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"data/MNIST/raw/train-labels-idx1-ubyte\",\"rb\") as f:\n",
    "    f.read(8) # here the first 8 bytes are header\n",
    "    labels_data = f.read()\n",
    "    labels = np.frombuffer(labels_data, dtype=np.uint8).copy() # converting labels to numpy array of type uint8\n",
    "    labels_tensor = torch.from_numpy(labels) # converting numpy array to pytorch tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b813487",
   "metadata": {},
   "source": [
    "## CREATING TENSOR DATASET AND LOADER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d436aa75",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "train_dataset = TensorDataset(images_tensor, labels_tensor) # pairing images with labels\n",
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True) # creating loader, it feeds data to the training loop, shuffle=True, shuffles the dataset at the start of each epoch,and returns dataset with a bs of 64, minibatch training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed65928b",
   "metadata": {},
   "source": [
    "## FLATTEN 28*28 PIXEL IMAGES TO 784 ELEMENT VECTOR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef79ffae",
   "metadata": {},
   "outputs": [],
   "source": [
    "## building the network\n",
    "## 10 output classes 0-9\n",
    "## 28 * 28 = 784 inputs\n",
    "\n",
    "model = nn.Sequential( # stacking layers in order\n",
    "    nn.Flatten(), # reshapes (batch, 1, 28, 28) → (batch, 784)\n",
    "    nn.Linear(28*28,128), # linear layer, Input: 784 features (pixels), Output: 128 features (the “hidden units”).\n",
    "    nn.ReLU(), # Activation function: Rectified Linear Unit.\n",
    "    nn.Linear(128,64), # Takes 128 inputs → outputs 64 hidden features.\n",
    "    nn.ReLU(), # Activation function: Rectified Linear Unit.\n",
    "    nn.Linear(64,10) # Takes 64 inputs → outputs 10 hidden features.\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "135e7d58",
   "metadata": {},
   "source": [
    "### Input layer: 784 neurons (flattened pixels).\n",
    "\n",
    "### Hidden layer 1: 128 neurons + ReLU.\n",
    "\n",
    "### Hidden layer 2: 64 neurons + ReLU.\n",
    "\n",
    "### Output layer: 10 neurons (one per digit)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb4e2933",
   "metadata": {},
   "source": [
    "## LOSS FUNCTION AND OPTIMIZER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a62ac62",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss() #loss function, Applies softmax internally to turn them into probabilities.\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001) # Adam (Adaptive Moment Estimation), combines the benefits of Momentum (smoother updates) and RMSProp (adaptive learning rates per parameter)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "381c5490",
   "metadata": {},
   "source": [
    "### criterion: Measures how wrong the model is (loss).\n",
    "\n",
    "### optimizer: Adjusts the model’s parameters to reduce that loss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "806df8a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): Flatten(start_dim=1, end_dim=-1)\n",
       "  (1): Linear(in_features=784, out_features=128, bias=True)\n",
       "  (2): ReLU()\n",
       "  (3): Linear(in_features=128, out_features=64, bias=True)\n",
       "  (4): ReLU()\n",
       "  (5): Linear(in_features=64, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\" ## checking if cuda is available, if not use cpu\n",
    "model.to(device) # Moves all the parameters (weights & biases) of your model onto the chosen device, cpu in my case"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ea8b068",
   "metadata": {},
   "source": [
    "## TRAINING LOOP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "782eb497",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 0.0107\n",
      "Epoch 2, Loss: 0.0108\n",
      "Epoch 3, Loss: 0.0084\n",
      "Epoch 4, Loss: 0.0098\n",
      "Epoch 5, Loss: 0.0102\n",
      "Epoch 6, Loss: 0.0058\n",
      "Epoch 7, Loss: 0.0067\n",
      "Epoch 8, Loss: 0.0109\n",
      "Epoch 9, Loss: 0.0062\n",
      "Epoch 10, Loss: 0.0045\n",
      "Epoch 11, Loss: 0.0086\n",
      "Epoch 12, Loss: 0.0087\n",
      "Epoch 13, Loss: 0.0051\n",
      "Epoch 14, Loss: 0.0026\n",
      "Epoch 15, Loss: 0.0087\n",
      "Epoch 16, Loss: 0.0048\n",
      "Epoch 17, Loss: 0.0074\n",
      "Epoch 18, Loss: 0.0052\n",
      "Epoch 19, Loss: 0.0015\n",
      "Epoch 20, Loss: 0.0095\n",
      "Epoch 21, Loss: 0.0052\n",
      "Epoch 22, Loss: 0.0059\n",
      "Epoch 23, Loss: 0.0056\n",
      "Epoch 24, Loss: 0.0059\n",
      "Epoch 25, Loss: 0.0033\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(25):  # loop for 15 epoch\n",
    "    running_loss = 0.0 # accumulate the loss over the batches in the epoch.\n",
    "    for images, labels in train_loader: # Loops over the training data in batches (64 images per batch in my loader).\n",
    "        images, labels = images.to(device), labels.to(device) # moving them to the device, cpu in my case\n",
    "\n",
    "        optimizer.zero_grad()      # Clears out the previous gradients, pytorch accumulates them\n",
    "        outputs = model(images)    # forward pass\n",
    "        loss = criterion(outputs, labels)  # Computes the loss (how wrong the predictions are) using CrossEntropyLoss.\n",
    "        loss.backward()            # Backpropagation step, Computes gradients of the loss w.r.t. all trainable parameters (weights & biases).\n",
    "        optimizer.step()           # Adam adjusts weights and biases to reduce the loss.\n",
    "\n",
    "        running_loss += loss.item() #Adds the scalar value of the loss for this batch to running_loss, .item() converts the tensor to a Python number.\n",
    "    print(f\"Epoch {epoch+1}, Loss: {running_loss/len(train_loader):.4f}\") # monitor training progress."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85153599",
   "metadata": {},
   "source": [
    "## LOADING TEST IMAGES AND LABELS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "623172df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test images\n",
    "with open(\"data/MNIST/raw/t10k-images-idx3-ubyte\",\"rb\") as f:\n",
    "    f.read(16)  #skipping the first 16 bytes which are header as it is image\n",
    "    test_data = f.read()\n",
    "    test_images = np.frombuffer(test_data, dtype=np.uint8).reshape(-1,1,28,28).astype(np.float32)/255.0 # converting images to numpy array  of type uint8 and reshaping and normalising in a single line\n",
    "    test_images_tensor = torch.from_numpy(test_images) # converting to torch tensor\n",
    "\n",
    "# Test labels\n",
    "with open(\"data/MNIST/raw/t10k-labels-idx1-ubyte\",\"rb\") as f:\n",
    "    f.read(8) #skipping the first 16 bytes which are header as it is label\n",
    "    test_labels_data = f.read()\n",
    "    test_labels = np.frombuffer(test_labels_data, dtype=np.uint8).copy() # converting label to numpy array  of type uint8\n",
    "    test_labels_tensor = torch.from_numpy(test_labels) # converting to torch tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "00afebed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): Flatten(start_dim=1, end_dim=-1)\n",
       "  (1): Linear(in_features=784, out_features=128, bias=True)\n",
       "  (2): ReLU()\n",
       "  (3): Linear(in_features=128, out_features=64, bias=True)\n",
       "  (4): ReLU()\n",
       "  (5): Linear(in_features=64, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.eval() # tells PyTorch that the model is now in evaluation/inference mode, not training mode."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ee6f67b",
   "metadata": {},
   "source": [
    "## METRICS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "622fb882",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.99      0.99       980\n",
      "           1       0.99      0.99      0.99      1135\n",
      "           2       0.96      0.98      0.97      1032\n",
      "           3       0.97      0.98      0.97      1010\n",
      "           4       0.98      0.98      0.98       982\n",
      "           5       0.99      0.97      0.98       892\n",
      "           6       0.99      0.97      0.98       958\n",
      "           7       0.98      0.98      0.98      1028\n",
      "           8       0.96      0.97      0.97       974\n",
      "           9       0.98      0.97      0.98      1009\n",
      "\n",
      "    accuracy                           0.98     10000\n",
      "   macro avg       0.98      0.98      0.98     10000\n",
      "weighted avg       0.98      0.98      0.98     10000\n",
      "\n",
      "F1 Score (macro): 0.9786076560237223\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, f1_score\n",
    "\n",
    "\n",
    "# empty lists for storing predictions and actual labels\n",
    "all_preds = []\n",
    "all_labels = []\n",
    "\n",
    "with torch.no_grad(): # We don’t need gradients during evaluation -> saves memory and speeds things up.\n",
    "    for images, labels in DataLoader(TensorDataset(test_images_tensor, test_labels_tensor), batch_size=64): # Creates a DataLoader for the test set (batch size 64), Iterates over mini-batches of test images & labels.\n",
    "        images = images.view(images.size(0), -1).to(device)  # flatten and move images to device: cpu\n",
    "        labels = labels.to(device) # move labels to cpu\n",
    "        outputs = model(images) # pass batch through network\n",
    "        preds = torch.argmax(outputs, dim=1) # get predictions\n",
    "        all_preds.extend(preds.cpu().numpy()) # store predictions\n",
    "        all_labels.extend(labels.cpu().numpy()) # store actual labels\n",
    "\n",
    "# Classification report\n",
    "print(classification_report(all_labels, all_preds))\n",
    "\n",
    "# F1 score (macro)\n",
    "print(\"F1 Score (macro):\", f1_score(all_labels, all_preds, average='macro'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba70e202",
   "metadata": {},
   "source": [
    "## INFERENCE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "99e1a36b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_image(image_path, device=\"cpu\"):\n",
    "    # Load image and convert to grayscale\n",
    "    img = Image.open(image_path).convert('L')  \n",
    "\n",
    "    # Resize to 28x28\n",
    "    img = img.resize((28, 28))  \n",
    "\n",
    "    # Convert to numpy array and normalize\n",
    "    img_array = np.array(img, dtype=np.float32) / 255.0  \n",
    "\n",
    "    # Flatten to 1D vector\n",
    "    img_flat = img_array.flatten()  \n",
    "\n",
    "    # Convert to PyTorch tensor and add batch dimension\n",
    "    img_tensor = torch.tensor(img_flat, dtype=torch.float32).unsqueeze(0).to(device)  \n",
    "\n",
    "    return img_tensor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4aacf462",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted digit: 9\n"
     ]
    }
   ],
   "source": [
    "from PIL import Image\n",
    "# Example image path\n",
    "image_path = \"data/images/9.jpg\" # Change the image name from 0-9 to test all numbers, eg: \"data/images/1.jpg\", \"data/images/3.jpg\"\n",
    "\n",
    "# Prepare image\n",
    "img_tensor = prepare_image(image_path, device=device) # processing image, resizing, converting to numpy, grayscaling, flattening, then tensor\n",
    "\n",
    "# Forward pass (no gradients needed)\n",
    "with torch.no_grad():\n",
    "    output = model(img_tensor)          # logits\n",
    "    predicted_class = torch.argmax(output, dim=1).item() # actual prediction\n",
    "\n",
    "print(f\"Predicted digit: {predicted_class}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4eb60422",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3706da90",
   "metadata": {},
   "source": [
    "## REFERENCE\n",
    "\n",
    "Each MNIST dataset file (`train-images-idx3-ubyte`, `train-labels-idx1-ubyte`, etc.) follows a specific binary structure.\n",
    "\n",
    "---\n",
    "\n",
    "### 1. **Image file (`*-images-idx3-ubyte`)**\n",
    "\n",
    "The first **16 bytes** are the header:\n",
    "\n",
    "| Offset (bytes) | Meaning             | Size |\n",
    "| -------------- | ------------------- | ---- |\n",
    "| 0–3            | Magic number (2051) | 4    |\n",
    "| 4–7            | Number of images    | 4    |\n",
    "| 8–11           | Rows per image (28) | 4    |\n",
    "| 12–15          | Cols per image (28) | 4    |\n",
    "\n",
    "* **16 bytes total header** → skipped with `f.read(16)` before reading actual pixel data.\n",
    "* Each pixel is 1 byte (unsigned 8-bit integer).\n",
    "* Total pixel data size: `num_images × 28 × 28` bytes.\n",
    "\n",
    "---\n",
    "\n",
    "### 2. **Label file (`*-labels-idx1-ubyte`)**\n",
    "\n",
    "The first **8 bytes** are the header:\n",
    "\n",
    "| Offset (bytes) | Meaning             | Size |\n",
    "| -------------- | ------------------- | ---- |\n",
    "| 0–3            | Magic number (2049) | 4    |\n",
    "| 4–7            | Number of labels    | 4    |\n",
    "\n",
    "* **8 bytes total header** → skipped with `f.read(8)`.\n",
    "* Each label is 1 byte (values 0–9).\n",
    "\n",
    "---\n",
    "\n",
    "### 3. **Data normalization**\n",
    "\n",
    "* MNIST pixel values range **0–255**.\n",
    "* Dividing by `255.0` scales them to **[0, 1]** for stable gradient learning.\n",
    "\n",
    "  ```python\n",
    "  images = images.astype(np.float32)/255.0\n",
    "  ```\n",
    "\n",
    "---\n",
    "\n",
    "### 4. **TensorDataset and DataLoader**\n",
    "\n",
    "* `TensorDataset(images_tensor, labels_tensor)` pairs **images with labels**.\n",
    "* `DataLoader(train_dataset, batch_size=64, shuffle=True)`:\n",
    "\n",
    "  * Provides **mini-batches** for training.\n",
    "  * Shuffling prevents the model from learning the order of samples.\n",
    "\n",
    "---\n",
    "\n",
    "### 5. **Model layers**\n",
    "\n",
    "* **Feedforward network (MLP)**:\n",
    "\n",
    "  ```python\n",
    "  nn.Flatten(),\n",
    "  nn.Linear(28*28,128),\n",
    "  nn.ReLU(),\n",
    "  nn.Linear(128,64),\n",
    "  nn.ReLU(),\n",
    "  nn.Linear(64,10)\n",
    "  ```\n",
    "* Fully connected layers + ReLU activations.\n",
    "* Input: 784 pixels → Hidden: 128 → 64 → Output: 10 logits (digits 0–9).\n",
    "\n",
    "---\n",
    "\n",
    "### 6. **Loss and optimizer**\n",
    "\n",
    "* `CrossEntropyLoss`: measures classification error for multi-class tasks.\n",
    "* `Adam optimizer`: adaptive gradient descent algorithm, updates model parameters.\n",
    "\n",
    "---\n",
    "\n",
    "### 7. **Device management**\n",
    "\n",
    "* `device = \"cuda\" if torch.cuda.is_available() else \"cpu\"` → selects GPU if available, else CPU.\n",
    "* `model.to(device)` moves the model to the selected device.\n",
    "* Data must also be moved to the same device for training/inference.\n",
    "\n",
    "---\n",
    "\n",
    "### 8. **Evaluation**\n",
    "\n",
    "* `model.eval()` → sets the model to **evaluation mode** (important if using Dropout/BatchNorm).\n",
    "* `torch.no_grad()` → disables gradient computation during testing → saves memory and speeds up inference.\n",
    "* Predictions and metrics:\n",
    "\n",
    "  ```python\n",
    "  classification_report(all_labels, all_preds)\n",
    "  f1_score(all_labels, all_preds, average='macro')\n",
    "  ```\n",
    "\n",
    "---\n",
    "\n",
    "### 9. **Inference**\n",
    "\n",
    "* `prepare_image` → processing image, resizing, converting to numpy, grayscaling, flattening, then tensor\n",
    "* `torch.no_grad()` → disables gradient computation during inference → saves memory and speeds up inference.\n",
    "* Predictions:\n",
    "\n",
    "  ```python\n",
    "    predicted_class = torch.argmax(output, dim=1).item() # actual prediction\n",
    "\n",
    "  ```\n",
    "\n",
    "---\n",
    "\n",
    "### 10. **Reference for MNIST Format**\n",
    "\n",
    "* Official MNIST description by Yann LeCun: [https://yann.lecun.org/exdb/mnist/index.html](https://yann.lecun.org/exdb/mnist/index.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6de86baa",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
